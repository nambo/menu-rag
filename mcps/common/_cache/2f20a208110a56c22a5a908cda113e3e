{"title": "AI“换装”损害军人警察形象 法律风险不容忽视", "url": "http://www.chinanews.com.cn/fz/2025/07-15/10447825.shtml", "source": "中国新闻网", "file_type": "htm", "key": "http://www.chinanews.com.cn/fz/2025/07-15/10447825.shtml", "handler": "news", "date": "2025-07-22", "summary": "**“灰犀牛”事件风险预警机制设计**\n\n在“人工智能+”政策实施过程中，需高度重视潜在的“灰犀牛”事件风险，即那些高概率发生、影响巨大但常被忽视的风险事件。本章基于历史数据与当前政策环境，识别影响政策实施效果的重大风险事件，并构建相应的风险预警指标体系。\n\nAI技术应用在公共领域迅速扩展，但也暴露出多重风险。例如，近期AI生成军人、警察形象的“换装”功能在短视频平台广泛传播，部分生成内容不当消费甚至亵渎职业形象，引发社会争议。此类行为不仅损害了军人、警察的职业尊严，也模糊了虚拟与现实界限，降低公众对执法机构的信任，影响社会稳定与法律执行效能。\n\n相关法律风险显著。AI生成内容若涉及他人肖像且未经授权，已构成对民法典中肖像权的侵犯。此外，若AI生成虚假执法内容，如捏造“酒驾被抓”“赌博被抓”等情节，可能违反《生成式人工智能服务管理暂行办法》，甚至构成诈骗罪或敲诈勒索罪。AI技术提供者若未对训练数据合法性进行审查，或未设置安全限制机制，亦可能承担连带法律责任。\n\n平台责任亦不容忽视。依据《互联网信息服务深度合成管理规定》及《生成式人工智能服务管理暂行办法》，平台需对AI生成内容进行标识，并对违法内容采取处置措施。若平台未履行审核义务，导致虚假、违法内容传播，将面临法律追责。\n\n为有效防控上述风险，需构建AI应用风险预警指标体系。该体系应包括以下维度：一是**内容合规性指标**，监测AI生成内容是否涉及特殊公职人员形象、是否符合着装规范、是否添加“AI生成”标识等；二是**法律风险指标**，评估内容是否涉及侵权、虚假信息传播及是否符合现行法律要求；三是**社会影响指标**，分析内容对公众认知、执法权威、社会秩序的潜在影响；四是**技术安全指标**，评估AI模型训练数据合法性、生成内容安全限制机制、平台审核能力等。\n\n政策层面，应强化AI产品合规审查机制。主管部门在审核涉及生成特殊公职人员形象的人工智能产品时，应设置技术门槛，要求具备内容合规检测功能。同时，完善标识制度，确保AI生成内容具备显式与隐式标识，便于公众识别。\n\n此外，应加强公众教育与引导。通过普法宣传提升民众对AI内容法律风险的认知，增强对军人、警察等职业形象的尊重意识，减少不当内容的传播。同时，普及AI内容识别方法，提高公众辨别能力，降低被误导或诈骗的风险。\n\n综上，AI“换装”乱象反映出当前AI技术应用在公共领域存在的系统性风险。构建科学的风险预警机制，结合法律规范、平台责任与公众教育，是保障“人工智能+”政策顺利实施的关键路径。"}